# ğŸŒ¬ï¸ Data Pipeline - Apache Airflow

IoT ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ Apache Airflow ê¸°ë°˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸

## ğŸ“‹ ê°œìš”

ì´ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ ì œì¡° í˜„ì¥ì˜ IoT ì„¼ì„œë¡œë¶€í„° ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘ë˜ëŠ” ì˜¨ë„ ë° ìŠµë„ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. Apache Airflowë¥¼ ì‚¬ìš©í•˜ì—¬ ETL(Extract, Transform, Load) í”„ë¡œì„¸ìŠ¤ë¥¼ ìë™í™”í•˜ê³ , ì‹œê°„ë³„ ë°ì´í„° ì§‘ê³„ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

-   **ì›Œí¬í”Œë¡œìš° ê´€ë¦¬**: Apache Airflow 2.10.3
-   **Executor**: Celery Executor (ë¶„ì‚° ì²˜ë¦¬)
-   **ë©”ì‹œì§€ ë¸Œë¡œì»¤**: Redis
-   **ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL
-   **ëª¨ë‹ˆí„°ë§**: Flower (Celery ëª¨ë‹ˆí„°ë§)
-   **ì»¨í…Œì´ë„ˆ**: Docker, Docker Compose
-   **ì–¸ì–´**: Python 3.x

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
data_pipeline/
â”œâ”€â”€ dags/                           # Airflow DAG ì •ì˜
â”‚   â””â”€â”€ flet_montrg/               # ì˜¨ë„ ëª¨ë‹ˆí„°ë§ DAG
â”‚       â”œâ”€â”€ flet_montrg_master_etl.py              # ë§ˆìŠ¤í„° ë°ì´í„° ETL
â”‚       â”œâ”€â”€ flet_montrg_temperature_etl.py         # ì˜¨ë„ ë°ì´í„° ETL (ë©”ì¸)
â”‚       â”œâ”€â”€ flet_montrg_temperature_backfill.py    # ì˜¨ë„ ë°ì´í„° ë°±í•„
â”‚       â”œâ”€â”€ flet_montrg_temperature_raw_etl.py     # Raw ë°ì´í„° ETL
â”‚       â””â”€â”€ flet_montrg_temperature_raw_backfill.py # Raw ë°ì´í„° ë°±í•„
â”‚
â”œâ”€â”€ plugins/                       # ì»¤ìŠ¤í…€ í”ŒëŸ¬ê·¸ì¸
â”‚   â””â”€â”€ hooks/                     # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í›…
â”‚       â”œâ”€â”€ postgres_hook.py       # PostgreSQL ì—°ê²°
â”‚       â”œâ”€â”€ mysql_hook.py          # MySQL ì—°ê²°
â”‚       â”œâ”€â”€ mssql_hook.py          # MS SQL Server ì—°ê²°
â”‚       â””â”€â”€ oracle_hook.py         # Oracle ì—°ê²°
â”‚
â”œâ”€â”€ db/                            # ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ flet_montrg/              # ì˜¨ë„ ëª¨ë‹ˆí„°ë§ ìŠ¤í‚¤ë§ˆ
â”‚       â”œâ”€â”€ README.md             # ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ
â”‚       â””â”€â”€ hq_flet_montrg_ERD.pdf # ERD ë‹¤ì´ì–´ê·¸ë¨
â”‚
â”œâ”€â”€ scripts/                       # ì„¤ì¹˜ ë° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ install_pymodbus.sh       # Modbus ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
â”‚   â”œâ”€â”€ install_pymodbustcp.sh    # Modbus TCP ì„¤ì¹˜
â”‚   â””â”€â”€ oracledb_setting.sh       # Oracle DB ì„¤ì •
â”‚
â”œâ”€â”€ oracle/                        # Oracle ê´€ë ¨ ì„¤ì •
â”‚   â””â”€â”€ ORACLE_INSTANT_CLIENT_SETUP.md
â”‚
â”œâ”€â”€ docker-compose.yml             # Airflow ì„œë¹„ìŠ¤ êµ¬ì„±
â”œâ”€â”€ Dockerfile                     # ì»¤ìŠ¤í…€ Airflow ì´ë¯¸ì§€
â”œâ”€â”€ requirements.txt              # Python ì˜ì¡´ì„±
â””â”€â”€ README.md                     # ì´ ë¬¸ì„œ
```

## ğŸ”„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¡°

### ë°ì´í„° íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ IoT Sensors â”‚ --> â”‚ PostgreSQL   â”‚ --> â”‚ Airflow DAGs  â”‚ --> â”‚ PostgreSQL   â”‚
â”‚             â”‚     â”‚ (Raw Data)   â”‚     â”‚ (ETL Process) â”‚     â”‚ (Processed)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â”‚
                                          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                          â”‚   API       â”‚
                                          â”‚  Services   â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š ì£¼ìš” DAG ì„¤ëª…

### 1. flet_montrg_temperature_etl.py

**ëª©ì **: ì‹œê°„ë³„ ì˜¨ë„ ë°ì´í„° ì§‘ê³„ ë° ì²˜ë¦¬ (ë©”ì¸ íŒŒì´í”„ë¼ì¸)

**ì‹¤í–‰ ì£¼ê¸°**: 1ì‹œê°„ë§ˆë‹¤

**ì²˜ë¦¬ ë‹¨ê³„**:

1. **Connection Check**: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
    - Source DB (pg_fdw_v1_iot): Raw ë°ì´í„°
    - Target DB (pg_fdw_v2_hq): ì§‘ê³„ ë°ì´í„°
2. **Data Extraction**: Raw ë°ì´í„° ì¶”ì¶œ

    ```sql
    -- ì‹œê°„ ë²”ìœ„ì˜ Raw ë°ì´í„° ì¡°íšŒ
    SELECT
        loc_id,
        temperature,
        humidity,
        pcv_temperature,
        capture_dt
    FROM flet_montrg.temperature_raw
    WHERE capture_dt >= :start_time
      AND capture_dt < :end_time
    ```

3. **Data Transformation**: ì‹œê°„ë³„ ì§‘ê³„

    ```sql
    -- ìœ„ì¹˜ë³„, ì‹œê°„ë³„ ì§‘ê³„
    SELECT
        loc_id,
        TO_CHAR(capture_dt, 'YYYYMMDD') as ymd,
        TO_CHAR(capture_dt, 'HH24') as hh,
        MAX(temperature) as temperature_max,
        AVG(temperature) as temperature_avg,
        MAX(humidity) as humidity_max,
        AVG(humidity) as humidity_avg,
        MAX(pcv_temperature) as pcv_temperature_max,
        AVG(pcv_temperature) as pcv_temperature_avg
    GROUP BY loc_id, ymd, hh
    ```

4. **Data Loading**: ì§‘ê³„ ë°ì´í„° ì ì¬

    - Upsert ë°©ì‹ìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€
    - ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸

5. **Data Validation**: ë°ì´í„° ê²€ì¦
    - ì ì¬ëœ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
    - ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

**DAG ì„¤ì •**:

```python
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'retries': 2,
    'retry_delay': timedelta(minutes=2),
    'execution_timeout': timedelta(minutes=30),
    'sla': timedelta(minutes=60)
}

schedule_interval = '0 * * * *'  # ë§¤ ì‹œê°„ ì •ê°
```

### 2. flet_montrg_temperature_backfill.py

**ëª©ì **: ê³¼ê±° ë°ì´í„° ì¬ì²˜ë¦¬ (ë°±í•„)

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**:

-   ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ë°œê²¬ ì‹œ ì¬ì²˜ë¦¬
-   ì§‘ê³„ ë¡œì§ ë³€ê²½ í›„ ê³¼ê±° ë°ì´í„° ì¬ê³„ì‚°
-   ì‹œìŠ¤í…œ ì¥ì•  ë³µêµ¬ í›„ ëˆ„ë½ ë°ì´í„° ì²˜ë¦¬

**íŠ¹ì§•**:

-   ë‚ ì§œ ë²”ìœ„ ì§€ì • ê°€ëŠ¥
-   ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
-   ì§„í–‰ ìƒí™© ë¡œê¹…

**ì‹¤í–‰ ë°©ë²•**:

```python
# Airflow Variable ì„¤ì •
backfill_start_date = '2024-01-01'
backfill_end_date = '2024-01-31'

# DAG ì‹¤í–‰
airflow dags backfill flet_montrg_temperature_backfill \
    --start-date 2024-01-01 \
    --end-date 2024-01-31
```

### 3. flet_montrg_temperature_raw_etl.py

**ëª©ì **: Raw ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬

**ì²˜ë¦¬ ë‚´ìš©**:

-   IoT ì„¼ì„œ ë°ì´í„° ì›ë³¸ ìˆ˜ì§‘
-   ë°ì´í„° í˜•ì‹ ê²€ì¦
-   ì´ìƒì¹˜ í•„í„°ë§ (ì„ íƒì )
-   Raw ë°ì´í„° í…Œì´ë¸” ì ì¬

### 4. flet_montrg_master_etl.py

**ëª©ì **: ë§ˆìŠ¤í„° ë°ì´í„° ë™ê¸°í™”

**ì²˜ë¦¬ ë‚´ìš©**:

-   ì„¼ì„œ ìœ„ì¹˜ ì •ë³´ ì—…ë°ì´íŠ¸
-   ì„¼ì„œ ë©”íƒ€ë°ì´í„° ë™ê¸°í™”
-   ì„ê³„ì¹˜ ì„¤ì • ì—…ë°ì´íŠ¸

## ğŸ”Œ ì»¤ìŠ¤í…€ Hooks

### PostgresHelper (postgres_hook.py)

PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¿¼ë¦¬ ì‹¤í–‰ì„ ìœ„í•œ í—¬í¼ í´ë˜ìŠ¤

**ì£¼ìš” ë©”ì„œë“œ**:

```python
class PostgresHelper:
    def __init__(self, conn_id: str):
        """ì—°ê²° IDë¡œ ì´ˆê¸°í™”"""

    def execute_query(self, sql: str, **context) -> List[Dict]:
        """SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""

    def execute_insert(self, table: str, data: List[Dict], **context):
        """ë°ì´í„° ì‚½ì…"""

    def execute_upsert(self, table: str, data: List[Dict],
                      conflict_columns: List[str], **context):
        """Upsert (Insert or Update)"""

    def check_table(self, schema: str, table: str) -> bool:
        """í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
```

**ì‚¬ìš© ì˜ˆì‹œ**:

```python
from plugins.hooks.postgres_hook import PostgresHelper

# ì´ˆê¸°í™”
pg_helper = PostgresHelper(conn_id='pg_fdw_v1_iot')

# ë°ì´í„° ì¡°íšŒ
result = pg_helper.execute_query(
    sql="SELECT * FROM flet_montrg.temperature_raw LIMIT 10",
    **context
)

# ë°ì´í„° ì‚½ì… (Upsert)
pg_helper.execute_upsert(
    table='flet_montrg.temperature',
    data=aggregated_data,
    conflict_columns=['loc_id', 'ymd', 'hh'],
    **context
)
```

### ì§€ì› ë°ì´í„°ë² ì´ìŠ¤

-   **PostgreSQL**: `postgres_hook.py`
-   **MySQL**: `mysql_hook.py`
-   **MS SQL Server**: `mssql_hook.py`
-   **Oracle**: `oracle_hook.py`

## âš™ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰

### 1. ì‚¬ì „ ìš”êµ¬ì‚¬í•­

-   Docker ë° Docker Compose ì„¤ì¹˜
-   ìµœì†Œ 4GB RAM ê¶Œì¥
-   PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ (Source & Target)

### 2. í™˜ê²½ ì„¤ì •

**.env íŒŒì¼ ìƒì„±**:

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow

# Celery ì„¤ì •
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres/airflow

# Executor ì„¤ì •
AIRFLOW__CORE__EXECUTOR=CeleryExecutor

# ë³´ì•ˆ í‚¤ (ìƒì„± í•„ìš”)
AIRFLOW__CORE__FERNET_KEY=<your-fernet-key>
AIRFLOW__WEBSERVER__SECRET_KEY=<your-secret-key>

# ê¸°íƒ€ ì„¤ì •
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
```

**ë³´ì•ˆ í‚¤ ìƒì„±**:

```bash
# Airflow ì»¨í…Œì´ë„ˆì— ì ‘ì†
docker exec -it <airflow-scheduler-container> bash

# Pythonìœ¼ë¡œ í‚¤ ìƒì„±
python << EOF
from cryptography.fernet import Fernet
print(f"FERNET_KEY: {Fernet.generate_key().decode()}")

import os
print(f"SECRET_KEY: {os.urandom(16).hex()}")
EOF
```

### 3. ë””ë ‰í† ë¦¬ ì¤€ë¹„

```bash
# í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ./dags ./logs ./plugins
```

### 4. Airflow ì´ˆê¸°í™” ë° ì‹¤í–‰

```bash
# Airflow ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
docker compose up airflow-init

# Airflow ì„œë¹„ìŠ¤ ì‹œì‘
docker compose up -d

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker compose ps

# Flower ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì„ íƒì‚¬í•­)
docker compose up -d airflow-flower
```

### 5. Worker ìŠ¤ì¼€ì¼ë§

```bash
# Worker ìˆ˜ ì¡°ì • (ì˜ˆ: 3ê°œ)
docker-compose up -d --scale airflow-worker=3 airflow-worker

# Worker ìƒíƒœ í™•ì¸
docker compose ps | grep worker
```

### 6. ì ‘ì† ì •ë³´

-   **Airflow UI**: http://localhost:8080
    -   ê¸°ë³¸ ê³„ì •: admin / admin (ë³€ê²½ ê¶Œì¥)
-   **Flower UI**: http://localhost:5555

## ğŸ”§ Airflow ì—°ê²°(Connection) ì„¤ì •

ì›¹ UIì—ì„œ Admin > Connectionsë¡œ ì´ë™í•˜ì—¬ ë‹¤ìŒ ì—°ê²°ì„ ì„¤ì •:

### PostgreSQL ì—°ê²°

**Connection ID**: `pg_fdw_v1_iot` (Raw Data Source)

-   Connection Type: Postgres
-   Host: your-postgres-host
-   Schema: flet_montrg
-   Login: your-username
-   Password: your-password
-   Port: 5432

**Connection ID**: `pg_fdw_v2_hq` (Processed Data Target)

-   Connection Type: Postgres
-   Host: your-postgres-host
-   Schema: flet_montrg
-   Login: your-username
-   Password: your-password
-   Port: 5432

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### ë¡œê·¸ í™•ì¸

```bash
# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸
docker compose logs -f airflow-scheduler
docker compose logs -f airflow-worker

# ëª¨ë“  ë¡œê·¸
docker compose logs -f

# ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜
./logs/dag_id=<dag_id>/run_id=<run_id>/task_id=<task_id>/
```

### DAG í…ŒìŠ¤íŠ¸

```bash
# DAG íŒŒì¼ êµ¬ë¬¸ ê²€ì‚¬
docker exec -it airflow-scheduler airflow dags list

# DAG ì •ë³´ í™•ì¸
docker exec -it airflow-scheduler airflow dags show flet_montrg_temperature_etl

# DAG í…ŒìŠ¤íŠ¸ ì‹¤í–‰
docker exec -it airflow-scheduler airflow dags test flet_montrg_temperature_etl 2024-01-01

# íŠ¹ì • Task í…ŒìŠ¤íŠ¸
docker exec -it airflow-scheduler airflow tasks test \
    flet_montrg_temperature_etl check_connections 2024-01-01
```

### Flower ëª¨ë‹ˆí„°ë§

Flower UI (http://localhost:5555)ì—ì„œ í™•ì¸ ê°€ëŠ¥:

-   Worker ìƒíƒœ ë° ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
-   Task ì‹¤í–‰ í†µê³„
-   Task í ìƒíƒœ
-   ì‹¤íŒ¨í•œ Task ë‚´ì—­

## ğŸš¨ ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

### 1. DAGê°€ ë³´ì´ì§€ ì•Šì„ ë•Œ

```bash
# Scheduler ì¬ì‹œì‘
docker compose restart airflow-scheduler

# DAG íŒŒì¼ ê¶Œí•œ í™•ì¸
ls -la ./dags/

# Scheduler ë¡œê·¸ í™•ì¸
docker compose logs airflow-scheduler | grep -i error
```

### 2. Task ì‹¤íŒ¨ ì‹œ

**í™•ì¸ ì‚¬í•­**:

1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ
2. ë°ì´í„° í˜•ì‹ ê²€ì¦
3. ë¦¬ì†ŒìŠ¤ ë¶€ì¡± (ë©”ëª¨ë¦¬/CPU)
4. íƒ€ì„ì•„ì›ƒ ì„¤ì •

**í•´ê²° ë°©ë²•**:

```bash
# Task ë¡œê·¸ í™•ì¸ (Web UI)
# Airflow UI > DAGs > [DAG ì´ë¦„] > Graph > [Task í´ë¦­] > Log

# Task ì¬ì‹¤í–‰
# Airflow UIì—ì„œ Clear ë²„íŠ¼ í´ë¦­
```

### 3. Worker ì—°ê²° ëŠê¹€

```bash
# Worker ìƒíƒœ í™•ì¸
docker compose ps airflow-worker

# Worker ì¬ì‹œì‘
docker compose restart airflow-worker

# Redis ì—°ê²° í™•ì¸
docker exec -it redis redis-cli ping
```

### 4. ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# Worker ìˆ˜ ì¤„ì´ê¸°
docker-compose up -d --scale airflow-worker=1 airflow-worker

# docker-compose.ymlì—ì„œ ë¦¬ì†ŒìŠ¤ ì œí•œ ì¡°ì •
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. Executor ìµœì í™”

**Celery Worker ì„¤ì •**:

```yaml
# docker-compose.yml
airflow-worker:
    environment:
        - AIRFLOW__CELERY__WORKER_CONCURRENCY=4
        - AIRFLOW__CELERY__WORKER_PREFETCH_MULTIPLIER=2
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

**Connection Pool ì„¤ì •**:

```ini
[core]
sql_alchemy_pool_size = 10
sql_alchemy_max_overflow = 20
sql_alchemy_pool_recycle = 3600
```

### 3. DAG ìµœì í™”

**ê¶Œì¥ ì‚¬í•­**:

-   Task ê°„ ë°ì´í„° ì „ë‹¬ì€ XCom ëŒ€ì‹  ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
-   í° ë°ì´í„°ì…‹ì€ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
-   ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ TaskëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰

## ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 1. ì¸ì¦ ì„¤ì •

**.env íŒŒì¼**:

```bash
# ê¸°ë³¸ ì¸ì¦ í™œì„±í™”
AIRFLOW__WEBSERVER__AUTHENTICATE=True
AIRFLOW__WEBSERVER__AUTH_BACKEND=airflow.contrib.auth.backends.password_auth

# RBAC í™œì„±í™”
AIRFLOW__WEBSERVER__RBAC=True
```

### 2. ì—°ê²° ì •ë³´ ì•”í˜¸í™”

-   Fernet Key ì‚¬ìš©
-   ConnectionsëŠ” Airflow ë©”íƒ€ë°ì´í„° DBì— ì•”í˜¸í™” ì €ì¥
-   ë¯¼ê° ì •ë³´ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬

### 3. ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ

```yaml
# docker-compose.yml
networks:
    airflow:
        driver: bridge
        internal: true # ì™¸ë¶€ ì ‘ê·¼ ì°¨ë‹¨
```

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ë¬¸ì„œ

-   [Database Schema](./db/flet_montrg/README.md)
-   [Oracle Setup Guide](./oracle/ORACLE_INSTANT_CLIENT_SETUP.md)

### ì°¸ê³  ìë£Œ

-   [Apache Airflow ê³µì‹ ë¬¸ì„œ](https://airflow.apache.org/docs/)
-   [Celery ê³µì‹ ë¬¸ì„œ](https://docs.celeryproject.org/)
-   [Docker Compose ë¬¸ì„œ](https://docs.docker.com/compose/)

## ğŸ¯ DAG ê°œë°œ ê°€ì´ë“œ

### ìƒˆë¡œìš´ DAG ì¶”ê°€

1. **DAG íŒŒì¼ ìƒì„±**: `./dags/` ë””ë ‰í† ë¦¬ì— Python íŒŒì¼ ìƒì„±
2. **DAG ì •ì˜**:

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'retries': 2,
    'retry_delay': timedelta(minutes=2),
}

with DAG(
    'my_new_dag',
    default_args=default_args,
    schedule_interval='0 * * * *',
    catchup=False,
    tags=['example', 'etl']
) as dag:

    def my_task(**context):
        # Task ë¡œì§
        pass

    task = PythonOperator(
        task_id='my_task',
        python_callable=my_task
    )
```

3. **DAG ê²€ì¦**: `airflow dags test my_new_dag 2024-01-01`
4. **í™œì„±í™”**: Web UIì—ì„œ DAG í† ê¸€ ON

### ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

1. **Idempotency**: TaskëŠ” ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„ ê°™ì€ ê²°ê³¼
2. **Atomicity**: TaskëŠ” ì™„ì „ ì„±ê³µ ë˜ëŠ” ì™„ì „ ì‹¤íŒ¨
3. **Logging**: ì¶©ë¶„í•œ ë¡œê·¸ ë©”ì‹œì§€ ì¶”ê°€
4. **Error Handling**: ì˜ˆì™¸ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
5. **Testing**: ìš´ì˜ ë°°í¬ ì „ ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸

## ğŸ“ ë¬¸ì˜ ë° ì§€ì›

ì´ìŠˆê°€ ìˆê±°ë‚˜ ê°œì„  ì œì•ˆì´ ìˆë‹¤ë©´ í”„ë¡œì íŠ¸ ë¦¬í¬ì§€í† ë¦¬ì˜ Issues ì„¹ì…˜ì„ í™œìš©í•´ì£¼ì„¸ìš”.

---

**Last Updated**: October 2025
